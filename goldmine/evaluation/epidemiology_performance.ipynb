{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First tests of inference methods on the epidemiology problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import corner\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics(simulator='epidemiology2d',\n",
    "                 method='maf',\n",
    "                 label='',\n",
    "                 reference_method='maf',\n",
    "                 reference_label='',\n",
    "                 single_theta=False):\n",
    "    \n",
    "    reference_path = '../data/results/' + simulator + '/' + reference_method + '/'\n",
    "    path = '../data/results/' + simulator + '/' + method + '/'\n",
    "    theta_label = '_singletheta' if single_theta else ''\n",
    "    \n",
    "    # Reference likelihood\n",
    "    log_p_references = []\n",
    "    for run in range(10):\n",
    "        run_label = '' if run == 0 else '_run_' +  str(run)\n",
    "        try:\n",
    "            log_p_references.append(np.load(path + 'log_p_hat' + theta_label + reference_label + run_label + '.npy'))\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    log_p_references = np.array(log_p_references)\n",
    "    \n",
    "    print(log_p_references.shape)\n",
    "    \n",
    "    log_p_reference = np.mean(log_p_references, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    expected_log_ps = []\n",
    "    roc_aucs = []\n",
    "    mses = []\n",
    "    \n",
    "    for run in range(10):\n",
    "        run_label = '' if run == 0 else '_run_' +  str(run)\n",
    "        try:\n",
    "            log_p = np.load(\n",
    "                path + 'log_p_hat' + theta_label + label + run_label + '.npy'\n",
    "            )\n",
    "            expected_log_ps.append(\n",
    "                1. / log_p.shape[0] * np.sum(log_p)\n",
    "            )\n",
    "            mses.append(\n",
    "                mean_squared_error(log_likelihood_reference, log_likelihood)\n",
    "            )\n",
    "            roc_aucs.append(\n",
    "                np.load(path + 'roc_auc_surrogate_vs_simulator_' + reference_label + run_label + '.npy')\n",
    "            )\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        \n",
    "    expected_log_ps = np.array(expected_log_ps)\n",
    "    roc_aucs = np.array(expected_log_ps)\n",
    "    mses = np.array(mses)\n",
    "        \n",
    "    # Calculate mean and std\n",
    "    expected_log_p_mean = np.mean(expected_log_ps)\n",
    "    expected_log_p_uncertainty = np.std(expected_log_ps) / len(expected_log_ps)**0.5\n",
    "    \n",
    "    mse_mean = np.mean(mses)\n",
    "    mse_uncertainty = np.std(msess) / len(mses)**0.5\n",
    "    \n",
    "    roc_auc_mean = np.mean(roc_aucs)\n",
    "    roc_auc_uncertainty = np.std(roc_aucs) / len(roc_aucs)**0.5\n",
    "    \n",
    "    return (expected_log_p_mean, expected_log_p_uncertainty,\n",
    "            mse_mean, mse_uncertainty,\n",
    "            roc_auc_mean, roc_auc_uncertainty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics as function of method and sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000]\n",
    "\n",
    "methods = ['histogram', 'histogram', 'maf', 'maf', 'scandal', 'scandal']\n",
    "filenames = ['', '_trainedonsingletheta', '', '_trainedonsingletheta', '', '_trainedonsingletheta']\n",
    "method_labels = ['Histo', 'Histo (trained on 1 theta)', 'MAF', 'MAF (trained on 1 theta)', 'SCANDAL', 'SCANDAL (trained on 1 theta)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f7959a8b2c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mreference_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mreference_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_trainedonsingletheta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0msingle_theta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             )\n\u001b[1;32m     23\u001b[0m         )\n",
      "\u001b[0;32m<ipython-input-7-3b8dd511463b>\u001b[0m in \u001b[0;36mload_metrics\u001b[0;34m(simulator, method, label, reference_method, reference_label, single_theta)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p_references\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlog_p_reference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p_references\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/higgs_inference/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2957\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/higgs_inference/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Make this warning show up first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/higgs_inference/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for method, filename in zip(methods, filenames):\n",
    "    metrics_this_method = []\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        \n",
    "        if sample_size == sample_sizes[-1]:\n",
    "            samplesize_label = '_trainingsamplesize_' + str(sample_size)\n",
    "        else:\n",
    "            samplesize_label = ''\n",
    "            \n",
    "        metrics_this_method.append(\n",
    "            load_metrics(\n",
    "                method=method,\n",
    "                label= filename + samplesize_label,\n",
    "                reference_method='maf',\n",
    "                reference_label='_trainedonsingletheta',\n",
    "                single_theta=True\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    metrics.append(metrics_this_method)\n",
    "    \n",
    "metrics = np.array(metrics)\n",
    "\n",
    "expected_log_p_mean = metrics[:,:,0]\n",
    "expected_log_p_uncertainty = metrics[:,:,1]\n",
    "mse_mean = metrics[:,:,2]\n",
    "mse_uncertainty = metrics[:,:,3]\n",
    "roc_auc_mean = metrics[:,:,4]\n",
    "roc_auc_uncertainty = metrics[:,:,5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs training sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,1)\n",
    "\n",
    "for m, method in enumerate(method_labels):\n",
    "    plt.fill_between(\n",
    "        sample_sizes,\n",
    "        - expected_log_p_mean[m] - expected_log_p_uncertainty[m],\n",
    "        - expected_log_p_mean[m] + expected_log_p_uncertainty[m],\n",
    "        color=colors[m],\n",
    "        alpha=0.3\n",
    "    )\n",
    "    \n",
    "for m, method in enumerate(method_labels):\n",
    "    plt.plot(\n",
    "        sample_sizes,\n",
    "        - expected_log_likelihoods[m],\n",
    "        color=colors[m]\n",
    "        lw=1.5,\n",
    "        ls='-',\n",
    "        marker='o',\n",
    "        ms=5.,\n",
    "        label=method\n",
    "    )\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Training sample size')\n",
    "plt.ylabel('Negative log likelihood')\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "\n",
    "for m, method in enumerate(method_labels):\n",
    "    plt.fill_between(\n",
    "        sample_sizes,\n",
    "        mse_mean[m] - mse_uncertainty[m],\n",
    "        mse_mean[m] + mse_uncertainty[m],\n",
    "        color=colors[m],\n",
    "        alpha=0.3\n",
    "    )\n",
    "    \n",
    "for m, method in enumerate(method_labels):\n",
    "    plt.plot(\n",
    "        sample_sizes,\n",
    "        mse_mean[m],\n",
    "        color=colors[m]\n",
    "        lw=1.5,\n",
    "        ls='-',\n",
    "        marker='o',\n",
    "        ms=5.,\n",
    "        label=method\n",
    "    )\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Training sample size')\n",
    "plt.ylabel('MSE (log likelihood) wrt high-statistics model')\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposy='clip')\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "\n",
    "for m, method in enumerate(method_labels):\n",
    "    plt.fill_between(\n",
    "        sample_sizes,\n",
    "        roc_auc_mean[m] - roc_auc_uncertainty[m],\n",
    "        roc_auc_mean[m] + roc_auc_uncertainty[m],\n",
    "        color=colors[m],\n",
    "        alpha=0.3\n",
    "    )\n",
    "    \n",
    "for m, method in enumerate(method_labels):\n",
    "    plt.plot(\n",
    "        sample_sizes,\n",
    "        roc_auc_mean[m],\n",
    "        color=colors[m]\n",
    "        lw=1.5,\n",
    "        ls='-',\n",
    "        marker='o',\n",
    "        ms=5.,\n",
    "        label=method\n",
    "    )\n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Training sample size')\n",
    "plt.ylabel('ROC AUC, simulator vs surrogate samples')\n",
    "ax.set_xscale(\"log\", nonposx='clip')\n",
    "    \n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original vs simulated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels=['Shannon diversity', '# strains', 'Carriage',\n",
    "        'Coinfection', 'Prevalence most common strain', '# singletons']\n",
    "x_ranges = [(0.8,3.0), (3.5,22.5), (0.5, 1.), (0.,0.4), (0.,0.6), (-0.5,12.5)]\n",
    "x_bins = [20, 19, 10, 7, 12, 12]\n",
    "\n",
    "x_simulator = np.load('../data/samples/epidemiology/x_test_singletheta.npy')\n",
    "x_maf = np.load('../data/results/epidemiology/maf/samples_from_p_hat_trainedonsingletheta.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(x_maf,\n",
    "                   labels=x_labels,\n",
    "                   range=x_ranges,\n",
    "                   bins=x_bins,\n",
    "                   color='C1', alpha=0.5)\n",
    "_ = corner.corner(x_simulator,\n",
    "                   fig=fig,\n",
    "                   labels=x_labels,\n",
    "                   range=x_ranges,\n",
    "                   bins=x_bins,\n",
    "                   color='C0', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
